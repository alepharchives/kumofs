?title kumofs
?author FURUHASHI Sadayuki

?css user.css

//*?kumofs user guide

*目次
^if_format html
#toc

*kumofsとは？
kumofsはkey-value型のデータを保存する高速な分散ストレージシステムです。
シンプルなデータしか保存できない代わりに、非常に高速で、簡単にスケールアウトできます。システムを止めることなくサーバーを追加したり、ダウンしたサーバーを復旧させることができます。
//少ない台数のサーバーでも運用でき、その後負荷に応じてサーバーを追加することで柔軟に性能を向上させていくことができます。また1台や2台のサーバーに障害が発生しても正常に動作し続ける耐障害性を持ち、単一点障害が一切ありません。1台のサーバーでも毎秒10万回以上の問い合わせに応答できる性能を持ち、低コストで極めて高速なストレージシステムを構築・運用できます。

*特徴とデータモデル
kumofsには以下のような特徴があります：
-サーバーを追加すると読み・書き両方の性能が向上します
-システムを止めずにサーバーを追加できます
-一部のサーバーがダウンしても正常に動き続けます
-小さなデータを大量に保存するのに適しています
-2台から60台程度までスケールします（60台以上はまだ検証していません）
-memcachedプロトコルを使ってアクセスできます

kumofsに保存できるデータは、''key''と''value''だけで表されるシンプルなデータです。以下の3つの操作をサポートしています：

::?Set(key, value)
::=keyとvalueのペアを保存します。１つのkey-valueペアは合計３台のサーバーにレプリケーションされます。
::=Set操作が成功すると、レプリケーション先のすべてのサーバーに同じkey-valueペアが保存され、その直後からどのクライアントからでも同じvalueをGetできます。
::=Set操作が失敗すると、そのkeyに対応するvalueは不定になります。そのkeyは再度Setするか、Deleteするか、Getしないようにしてください。
::?value = Get(key)
::=keyに対応するvalueを取得します。
::=Set中にGetした場合に古いvalueが取得されるか新しいvalueが取得されるかは不定です。ただし新旧が混ざったvalueにはなることはありません。
::?Delete(key, value)
::=keyに対応するvalueを削除します。
::=Delete操作は実際には「削除済みフラグをSet」する操作なので、Setと同じ挙動になります。削除済みフラグは一定の時間が経過すると本当に削除されます。

*インストール
//kumofsは以下のURLからダウンロードできます

kumofsをコンパイルして実行するには以下の環境が必要です：
-linux >= 2.6.18
-[[Tokyo Cabinet>http://tokyocabinet.sourceforge.net/]] >= 1.4.10
-[[MessagePack for Ruby>http://msgpack.sourceforge.jp/ruby:install.ja]] >= 0.3.1
-[[MessagePack for C++>http://msgpack.sourceforge.jp/cpp:install.ja]] >= 0.3.1（コンパイル時のみ）
-[[Ragel>http://www.complang.org/ragel/]] >= 6.3（コンパイル時のみ）
-g++ >= 4.1（コンパイル時のみ）
-ruby >= 1.8.7
-libcrypto (openssl)
-zlib

 ./configure && make && make install でインストールできます。
>|sh|
$ ./configure
$ make
$ sudo make install
||<

*チュートリアル
kumofsは主に以下の３つのプログラムで構成されています：
:kumo-server:実際にデータを保存するノード。少なくとも1台必要で、後から追加できる。
:kumo-manager:kumo-server群を管理するノード。1台または2台。
:kumo-gateway:アプリケーションからのリクエストをkumo-serverに中継するプロキシ。アプリケーションを動かすホスト上で起動しておく。

ここでは３台のサーバー '''svr1,svr2,svr3''' を使って分散ストレージを構築する方法を紹介します。'''svr1'''と'''svr2'''でkumo-managerを起動し、'''svr1,svr2,svr3'''でkumo-serverを起動します。それから別のクライアント'''cli1'''からデータを保存･取得してみます。

**kumo-managerを起動する
まず最初に'''svr1'''と'''svr2'''の２台のサーバーでkumo-managerを起動します。
kumo-managerには少なくとも自分のホスト名かIPアドレスと、もう１台のkumo-managerのホスト名かIPアドレスを指定します：
>|sh|
[svr1]$ kumo-manager -v -l svr1 -p svr2
[svr2]$ kumo-manager -v -l svr2 -p svr1
||<
kumo-managerは19700/tcpをlistenします（デフォルト値）。

**kumo-serverを起動する
次に'''svr1,svr2,svr3'''の３台のサーバーでkumo-serverを起動します。
kumo-serverには少なくとも自分のホスト名かIPアドレス、kumo-managerのホスト名かIPアドレス、データベースのパスを指定します：
>|sh|
[svr1]$ kumo-server -v -l svr1 -m svr1 -p svr2 -s /var/kumodb.tch
[svr2]$ kumo-server -v -l svr2 -m svr1 -p svr2 -s /var/kumodb.tch
[svr3]$ kumo-server -v -l svr3 -m svr1 -p svr2 -s /var/kumodb.tch
||<
kumo-serverは19800/tcpと19900/tcpをlistenします（デフォルト値）。

**kumo-serverを登録する
kumo-serverは起動しただけでは追加されません。''kumoctl''コマンドを使って登録します。
まずは''kumoctl''コマンドを使って、kumo-managerからkumo-serverが認識されているかどうかを確認してみます：
>|sh|
$ kumoctl svr1 status
hash space timestamp:
  Wed Dec 03 22:15:55 +0900 2008 clock 62
attached node:
not attached node:
  192.168.0.101:19800
  192.168.0.102:19800
  192.168.0.103:19800
||<
''not attached node'' のところに３台のサーバーが認識されていることを確認したら、実際に登録します：
>|sh|
$ kumoctl svr1 attach
||<
最後に本当に登録されたか確認します：
>|sh|
$ kumoctl svr1 status
hash space timestamp:
  Wed Dec 03 22:16:00 +0900 2008 clock 72
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
not attached node:
||<
無事 ''attached node'' のところに登録されました。

**kumo-gatewayの起動する
実際にアプリケーションからkumofsを利用するには、アプリケーションを動かすホストでkumo-gatewayを起動しておきます。kumo-gatewayはmemcachedプロトコルを実装しているので、アプリケーションからは ''localhostで動作しているmemcached'' に見えます。
kumo-gatewayには少なくともkumo-managerのホスト名かIPアドレスと、memcachedをlistenするポート番号を指定する必要があります。
>|sh|
[cli1]$ kumo-gateway -v -m svr1 -p svr2 -t 11211
||<

これでkumofsを利用する準備が整いました。'''cli1'''でlocalhostの11211番にmemcachedクライアントを使って接続してみてください。

*HowTo
**新しいkumo-serverを追加する
チュートリアルで構築したシステムに別のサーバー'''svr4'''を追加するには、まずkumo-serverを起動し、次にkumoctlコマンドを使って登録します：
>|sh|
[svr4]$ kumo-server -v -l svr4 -m svr1 -p svr2 -s /var/kumodb.tch
$ kumoctl svr1 attach
||<
これで新しいサーバーが追加されました。

**すべてのプロセスをlocalhostで動かす
すべてのプロセスを１台のホストで動かして試してみるには以下のようにします：
>|sh|
[localhost]$ kumo-manager -v -l localhost
[localhost]$ kumo-server  -v -m localhost -l localhost:19801 -L 19901 -s ./database1.tch
[localhost]$ kumo-server  -v -m localhost -l localhost:19802 -L 19902 -s ./database2.tch
[localhost]$ kumo-server  -v -m localhost -l localhost:19803 -L 19902 -s ./database3.tch
[localhost]$ kumo-gateway -v -m localhost -t 11211
||<

**ノードの死活状態を表示する
kumo-managerはクラスタ全体を管理しているノードです。kumo-managerの状態を取得することでクラスタ全体の状態を知ることができます。
ノードの状態を取得するには''kumoctl''コマンドを使います。第一引数にはkumo-manager（複数いる場合はどれか１台）のアドレスを指定し、第二引数には''status''と指定してください。
>|sh|
$ kumoctl svr1 status
hash space timestamp:
  Wed Dec 03 22:15:45 +0900 2008 clock 58
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (fault)
not attached node:
  192.168.0.104:19800
||<

::?hash space timestamp
::=このkumo-managerに登録されているkumo-serverの一覧が最後に更新された時刻。サーバーを追加したときとサーバーがダウンしたときに更新されます。
::?attached node
::=登録されているkumo-serverの一覧。''(active)''と表示されているノードは正常に動作しているノードで、''(fault)''と表示されているノードは障害が発生しているか障害が発生してからまだ再登録されていないノードです。
::?not attached node
::=認識されているがまだ登録されていないkumo-serverの一覧。

kumoctlコマンドの詳しい使い方はリファレンスを参照してください。

**ノードの負荷を表示する
kumo-serverは実際にデータを保存しているノードです。''kumostat''コマンドを使うと、そのkumo-serverに保存されているデータの件数や、今までに処理されたGet操作の累計回数などを取得できます。
>|sh|
$ kumostat svr3 items
$ kumostat svr3 cmd_get
||<

第１引数にはkumo-serverのアドレスを指定します。第２引数には主に以下のサブコマンドを指定できます：
:uptime:kumo-serverプロセスの起動時間（単位は秒）
:version:kumo-serverのバージョン
:cmd_get:Get操作を処理した累計回数
:cmd_set:Set操作を処理した累計回数
:cmd_delete:Delete操作を処理した累計回数
:items:データベースに保存されているデータの件数

kumostatコマンドの詳しい使い方はリファレンスを参照してください。

また''kumotop''コマンドを使うと、topコマンドのようにkumo-serverの負荷をモニタリングすることができます。
引数には''-m''に続いてkumo-managerのアドレスを指定するか、モニタしたいkumo-serverのアドレスを列挙します：
>||
$ kumotop -m svr1
||<

**あるデータがどのkumo-serverに保存されているか調べる
kumofsはデータを複数のkumo-serverに分散して保存します。あるkeyが実際にどのkumo-serverに保存されているかを調べるには、''kumohash''コマンドを使います：
>|sh|
$ kumohash -m svr1 assign "the-key"
||<

**バックアップから復旧する
コールドバックアップが役に立つのは、以下のような場面です：

-3台以上のkumo-serverのHDDが同時に壊れた
-そのほか何らかの原因でデータが消失した

バックアップを作成するには、'''kumoctl'''コマンドの''backup''サブコマンドを使います。するとそれぞれのkumo-serverでデータベースファイルのバックアップが作成されるので、これをscpなどを使って１台のホストに集め、''kumomergedb''コマンドを使って１つのデータベースファイルに結合します。

バックアップから復旧するときは、バックアップしておいたデータベースファイルをすべてのサーバーに配り、kumo-serverを起動します。このときすべてのkumo-serverは同じデータを持っており、そのkumo-serverが持っている必要が無いデータまで持っています。その後'''kumoctl'''コマンドの''attach''サブコマンドを使ってkumo-serverを登録すると、不要なデータが削除され、整合性のある状態に回復します。


*トラブルと復旧
**kumo-serverが1台か2台ダウンした
kumo-serverが1台ダウンすると、一部のkey-valueペアの複製が1つ減った状態のまま動作し続けます。2台ダウンすると、1つか2つ減った状態のままになります。この状態から複製の数を3つに戻すには、kumo-serverを復旧させたあとkumoctlコマンドを使って再度登録するか、ダウンしたkumo-serverを完全に切り離します。

まずはkumoctlコマンドを使ってどのkumo-serverに障害が発生しているのかを確認します：
>|sh|
[xx]$ kumoctl m1 status    # m1はkumo-managerのアドレス
hash space timestamp:
  Wed Dec 03 22:15:35 +0900 2008 clock 50
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (fault)
not attached node:
||<
''(fault)''と表示されているkumo-serverに障害が発生しています。

kumo-serverを復旧させて元の台数に戻すときは、まずデータベースファイルを削除するか移動させておき、その後でkumo-serverプロセスを再起動します。古いデータベースファイルが残っていると、削除したはずのデータが復活してしまう可能性があります。
kumo-serverを再起動するとkumoctlの表示は以下のようになります：
>|sh|
[xx]$ kumoctl m1 status
hash space timestamp:
  Wed Dec 03 22:15:45 +0900 2008 clock 58
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (fault)
not attached node:
  192.168.0.104:19800
||<
''not attached node''のところに表示されているkumo-serverは、kumo-managerから認識されているが、まだ登録されていないkumo-serverの一覧です。

ここで''attach''コマンドを発行すると、復旧したkumo-serverが実際に登録され、データの複製が3つになるようにコピーされます：
>|sh|
[xx]$ kumoctl m1 attach    # 復旧したkumo-serverを再登録
[xx]$ kumoctl m1 status
hash space timestamp:
  Wed Dec 03 22:15:55 +0900 2008 clock 62
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (active)
not attached node:
||<

ここでkumo-serverを登録するときに、データをコピーするために比較的大規模なネットワークトラフィックが発生することに注意してください。

kumoctlコマンドで、attachコマンドの代わりに''detach''コマンドを発行すると、fault状態のkumo-serverが切り離されます。このときも複製の数が3つになるようにデータのコピーが行われます。
>|sh|
[xx]$ kumoctl m1 detach    # 落ちたkumo-serverを完全に切り離し
[xx]$ kumoctl m1 status
hash space timestamp:
  Wed Dec 03 22:15:55 +0900 2008 clock 62
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
not attached node:
||<

**kumo-serverが3台以上ダウンした
kumo-serverが３台以上ダウンすると、一部のデータにアクセスできなくなります。しかしデータベースファイルが残っていればデータを復旧することはできます。
TODO

**kumo-managerがダウンした
FIXME
2台で冗長構成を取っているときに片方のkumo-managerがダウンしまった場合は、まずkumo-managerを再起動してください。kumo-managerのIPアドレスは障害発生前と同じにしておく必要があります。次に残っていた方のkumo-managerに対して'''kumoctl'''コマンドの''replace''サブコマンドを発行してください。これで２台のkumo-managerの情報が同期されます。

kumo-managerがすべてダウンしてしまってもシステムを止めることなく復旧できます。この場合は、まずダウンしているkumo-serverがいるときは再起動してください。次にkumo-managerをすべて再起動させてください。最後に'''kumoctl'''コマンドの''attach''サブコマンドを使ってkumo-serverを登録します。これで整合性のある状態に回復します。

**Setが必ず失敗する
何度やってもSet操作が必ず失敗してしまう場合は、以下の項目を調べてみてください：
:kumo-serverは登録されているか:'''kumoctl MANAGER status'''を使ってkumo-managerの状態を調べて、kumo-serverが'''attached node''として登録されており、'''(active)'''と表示されていることを確認してください。
:サーバーによってルーティング表が食い違っていないか:'''kumostat SERVER whs''' FIXME

**Setがたまに失敗する
memcachedのクライアントライブラリの実装によっては、デフォルトのタイムアウト時間が非常に短く設定されていることがあります。Set操作は比較的時間がかかるので、タイムアウトしてしまっている可能性があります。
memcachedのクライアントライブラリの設定で、タイムアウト時間を長くしてみてください。

**SetできるのにGetできない
kumofsは、Set/Delete操作用とGet操作用の２つのルーティング表を使っています。通常この２つは同じですが、サーバーの追加や復旧の処理中に通信エラーが発生すると、2つのルーティング表が食い違ってしまうことが有り得ます。
'''kumostat'''コマンドの''hscheck''サブコマンドを使うと、２つのルーティング表が食い違っていないかを確認することができます。
もし食い違っていた場合は、'''kumoctl'''コマンドの''replace''サブコマンドを使うと修復できます。

**データベースファイルには保存されているのにGetできないkeyがある
kumofsはデータを複数のkumo-serverに分散して保存しますが、保存するときに所定のkumo-serverに保存し、取得するときは所定のkumo-serverに保存されていることを前提とします。このため何らかの理由でデータが所定のkumo-serverとは違うkumo-serverに保存されていると、そのデータはデータベースファイルには保存されていても取得できません。
'''kumoctl'''コマンドの''full-replace''サブコマンドを使うと修復できます。ただしfull-replaceを使うと大きなネットワークトラフィックが発生するので注意してください。

*性能とチューニング
**性能の見積もり
kumofsは１台の AMD Athlon64 X2 5000+ を搭載したサーバーを使って、1秒間に約5万回のGet操作を処理できます。このスループットはkumo-serverを追加するごとにほぼ線形に向上するので、5台のサーバーを使えば1秒間に約25万回のGet操作を処理できます。Set操作とDelete操作のスループットは、Get操作の約3分の1になります。
このスループットを発揮するには、すべてのデータがキャッシュメモリに収まっている必要があります。1つのデータは3つにレプリケーションされるので、1GBのデータを保存するには3GBの容量を必要とします。また1つのデータはアラインメントが取られて保存されるため、1つのデータのサイズは16バイトの倍数（デフォルト）に切り上げられます。
ここから計算すると、例えば１つのデータのサイズが160バイトで、2GBのメモリを搭載したサーバーを5台用意すると、2GB * 5台 / 3レプリカ / 160バイト = 2236万件 までのデータがキャッシュメモリに収まります。

**データベースファイルのチューニング
Tokyo Cabinetのハッシュデータベースのチューニングによって、性能が大きく変わります。データベースをチューニングするには、kumo-serverを起動する前に、''tchmgr''コマンドを使ってデータベースファイルをあらかじめ作成しておきます。
最も重要なのはバケット数のチューニングです。  FIXME
Tokyo Cabinetのパラメータのうち、拡張メモリマップのサイズ（xmsiz）とキャッシュ機構（rcnum）はkumo-serverのコマンドライン引数で指定します。kumo-serverの''-s''オプションで、データベースファイル名の後ろに''#xmsiz=XXX''と指定すると拡張メモリマップのサイズを指定できます。''#rcnum=XXX''と指定するとキャッシュ機構を有効化できます。
>|sh|
[svr1]$ kumo-server -v -m mgr -l svr1 -s "database.tch#xmsiz=600m#rcnum=4k"
||<
詳しいパラメータについてはTokyo Cabinetのドキュメントを参照してください。

**スレッド数のチューニング
CPUのコア数が多い場合は、kumo-serverやkumo-gatewayのワーカースレッドの数（-TR引数）を増やすと性能が向上します。CPUのスレッド数+2 くらいが目安です。デフォルトは4です。
保存するデータのサイズが大きい場合は、kumo-serverやkumo-gatewayの送信用スレッドの数（-TW引数）を増やすと性能が向上する可能性があります。デフォルトは2です。

*コマンドリファレンス
**configureフラグ
:--with-tokyocabinet=DIR:Tokyo Cabinetがインストールされているディレクトリを指定する
:--with-msgpack=DIR:MessagePackがインストールされているディレクトリを指定する
:--with-tcmalloc[=DIR]:tcmallocとリンクする
:--enable-trace:画面を埋め尽くすほど冗長なデバッグ用のメッセージを出力するようにする

**共通のコマンドライン引数
:-o <path.log>:ログを標準出力ではなく指定されたファイルに出力する。''-''を指定すると標準出力に出力する。省略するとログに色を付けて標準出力に出力する
:-v:WARNよりレベルの低いメッセージを出力する
:-g <path.mpac>:バイナリログを指定されたファイルに出力する
:-d <path.pid>:デーモンになる。指定されたファイルにpidを書き出す
:-Ci <sec>:タイマークロックの間隔を指定する。単位は秒で、整数か小数を定できる
:-Ys <sec>:connect(2)のタイムアウト時間を指定する。単位は秒で、整数か小数を指定できる
:-Yn <num>:connect(2)のリトライ回数を指定する
:-TR <num>:ワーカースレッドの数を指定する
:-TW <num>:送信用スレッドの数を指定する

**kumo-manager
:-l <address>:待ち受けるアドレス。''他のノードから見て''接続できるホスト名とポート番号を指定する
:-p <address>:もし存在するなら、もう一台のkumo-managerのホスト名とポート番号を指定する
:-c <port>:kumoctlからのコマンドを受け付けるポート番号を指定する
:-a:Serverが追加・離脱されたときに、マニュアル操作を待たずにレプリケーションの再配置を自動的に行うようにする。実行中でもkumoctlコマンドを使って変更できる
:-Rs:自動的な再配置が有効なときに、サーバーの追加・離脱を検出してからレプリケーションの再配置を開始するまでの待ち時間を指定する。単位は秒

**kumo-server
:-l <address>:待ち受けるアドレス。''他のノードから見て''接続できるホスト名とポート番号を指定する
:-L <port>:kumo-serverが待ち受けるもう一つのポートのポート番号を指定する
:-m <address>:kumo-managerのホスト名とポート番号を指定する
:-p <address>:もし存在するなら、もう一台のkumo-managerのホスト名とポート番号を指定する
:-s <path.tch[#xmsiz=SIZE][#rcnum=SIZE]>:データを保存するデータベースファイルのパスを指定する
:-f <dir>:レプリケーションの再配置に使う一時ファイルを保存するディレクトリを指定する。データベースファイルのサイズに応じて十分な空き容量が必要
:-gS <seconds>:deleteしたエントリのクロックを保持しておくメモリ使用量の上限をKB単位で指定する
:-gN <seconds>:deleteしたエントリのクロックを保持しておく最小時間を指定する。メモリ使用量が上限に達していると、最大時間に満たなくても最小時間を過ぎていれば削除される。
:-gX <seconds>:deleteしたエントリのクロックを保持しておく最大時間を指定する

***削除済みフラグの回収
Delete操作は実際には削除済みフラグをSetする操作です。しかし削除済みフラグは時間が経過すると回収され、本当に削除されます。削除済みフラグが回収されると一貫性は保証されません。削除済みフラグは以下の条件で回収されます：
:Deleteしてから一定の時間が経過した:この時間はkumo-serverの''-gX''オプションで指定できます。
:Deleteフラグを記憶するメモリ使用量の上限に達し、かつDeleteしてから一定の時間が経過した:この時間はkumo-serverの''-gN''オプションで指定できます。メモリ使用量の上限は''-gS''オプションで指定できます。
削除済みフラグを記憶するメモリ使用量の上限に達したが、Deleteしてから一定の時間が経過していない場合は、削除済みフラグはデータベースファイルの中に放置されます。放置された削除済みフラグは、次に再配置操作が行われたときに回収されます。

**kumo-gateway
:-m <address>:kumo-managerのホスト名とポート番号を指定する
:-p <address>:もし存在するなら、もう一台のkumo-managerのホスト名とポート番号を指定する
:-t <port>:memcachedテキストプロトコルを待ち受けるポート番号を指定する
:-b <port>:memcachedバイナリプロトコルを待ち受けるポート番号を指定する（EXPERIMENTAL）
:-G <number>:Get操作の最大リトライ回数を指定する
:-S <number>:Set操作の最大リトライ回数を指定する
:-D <number>:Delete操作の最大リトライ回数を指定する
:-As:Set操作でレプリケーションするとき、レプリケーション完了の応答を待たずに成功を返すようにする
:-Ad:Delete操作でレプリケーションするとき、レプリケーション完了の応答を待たずに成功を返すようにする

***非同期レプリケーション
kumofsではデータをsetしたりdeleteしたりするときレプリケーションを行いますが、デフォルトではレプリケーションが完了するまで待ってから（すべてのサーバーから応答が帰ってきてから）アプリケーションに応答が返されます。これを1台のkumo-serverに書き込みが完了した時点で応答を返すようにすると（非同期レプリケーション）、更新系の応答時間が大幅に短縮されます。
ただし非同期レプリケーションを有効にすると、成功応答が帰ってきたとしても、必ずしもレプリケーションが成功していることが保証されず、そのため複数のkumo-server間でデータの一貫性が保たれているとが保証されなくなります。
Set操作のレプリケーションを非同期にするには、kumo-gatewayのコマンドライン引数に''-As''を、Delete操作のレプリケーションを非同期にするには''-Ad''を追加してください。

**kumoctl
kumoctlコマンドはkumo-managerに様々なコマンドを発行するための管理コマンドです。
第一引数にkumo-managerのアドレスを指定し、第二引数にサブコマンドを指定します。
>|sh|
Usage: kumoctl address[:port=19799] command [options]
command:
   status                     get status
   attach                     attach all new servers and start replace
   attach-noreplace           attach all new servers
   detach                     detach all fault servers and start replace
   detach-noreplace           detach all fault servers
   replace                    start replace without attach/detach
   full-replace               start full-replace (repair consistency)
   backup  [suffix=????????]  create backup with specified suffix
   enable-auto-replace        enable auto replace
   disable-auto-replace       disable auto replace
||<

''attach''サブコマンドは、認識しているが登録されていないkumo-serverを実際に登録します。''detach''サブコマンドは、fault状態のkumo-serverを切り離します。
''attach-noreplace''サブコマンドは''attach''と同じですが、kumo-serverを登録した後にkey-valueペアの複製の再配置を行いません。''detach-noreplace''サブコマンドは''detach''と同じですが、kumo-serverを切り離した後に複製の再配置を行いません。
''replace''サブコマンドは複製の再配置だけを行います。
attach-noreplaceサブコマンドとdetach-noreplaceサブコマンドはattachとdetachを同時に行いときのみ使用し、すぐにreplaceサブコマンドを使って再配置を行ってください。再配置を行わないまま長い間放置してはいけません。
''backup''サブコマンドは、データベースファイルのバックアップを作成します。バックアップは認識しているすべてのServerノード上で作成されます。
バックアップファイルのファイル名は、元のデータベースファイル名に第三引数で指定したsuffixを付けたファイル名になります。suffixを省略するとその日の日付(YYMMDD)が使われます。
作成されたバックアップファイルは、''kumomergedb''コマンドを使って1つのファイルにまとめることができます。

**kumostat
FIXME
kumostatコマンドを使うとkumo-serverの状態を取得することができます。
第一引数にkumo-serverのホスト名とポート番号を指定し、第二引数にコマンドを指定します：
>||
Usage: kumostat server-address[:port=19800] command
       kumostat -m manager-address[:port=19700] command
command:
   pid                        get pid of server process
   uptime                     get uptime
   time                       get UNIX time
   version                    get version
   cmd_get                    get number of get requests
   cmd_set                    get number of set requests
   cmd_delete                 get number of delete requests
   items                      get number of stored items
   rhs                        get rhs (routing table for Get)"
   whs                        get whs (routing table for Set/Delete)"
   hscheck                    check if rhs == whs
   set_delay                  maximize throughput at the expense of latency"
   unset_delay                minimize latency at the expense of throughput"
||<

''-m''に続いてkumo-managerのアドレスを指定すると、kumo-managerからkumo-server一覧を取得し、attachされていてactiveなすべてのkumo-serverの状態を表示します。

:pid:kumo-serverプロセスのpid
:uptime:kumo-serverプロセスの起動時間（単位は秒）
:time:kumo-serverプロセスが走っているホストのUNIXタイム
:version:kumo-serverのバージョン
:cmd_get:GatewayノードからのGet操作を処理した回数
:cmd_set:GatewayノードからのSet操作を処理した回数
:cmd_delete:GatewayノードからのDelete操作を処理した回数
:items:データベースに入っているエントリの数
:rhs:Getに使われるルーティング表
:whs:Set/Deleteに使われるルーティング表
:hscheck:rhsとwhsが同じかどうかチェックします
:set_delay:遅延を犠牲にして最大スループットを最大化する
:unset_delay:最大スループットを犠牲にして遅延を最小化する

rhsとwhsが食い違っている場合は、再配置を実行中か、前回の再配置が失敗している可能性があります。

**kumotop
FIXME
kumotopコマンドを使うとkumo-serverの状態を定期的に更新しながら表示することができます。
引数に監視したいkumo-serverのアドレスを指定します。kumo-serverのアドレスは複数指定できます：
>||
Usage: kumotop server-address[:port=19800] ...
       kumotop -m manager-address[:port=19700]
||<

''-m''に続いてkumo-managerのアドレスを指定すると、kumo-managerからServer一覧を取得し、attachされているすべてのServerノードの状態を表示します。

**kumomergedb
FIXME
kumomergedbコマンドを使うと、複数のデータベースファイルを1つにまとめることができます。第一引数に出力先のファイル名を指定し、第二引数以降にまとめたいデータベースファイルを指定します。
>|sh|
$ kumomergedb backup.tch-20090101 \
              server1.tch-20090101 server2.tch-20090101 server3.tch-20090101
||<

**kumohash
kumohashコマンドを使うと、あるkeyがどのkumo-serverに保存されるかを計算することができます。
>||
Usage: kumohash server-address[:port=19800] ... -- command [options]
       kumohash -m manager-address[:port=19700] command [options]
command:
   hash  keys...              calculate hash of keys
   assign  keys...            calculate assign node
   dump                       dump hash space
||<

:hash:keyのハッシュ値を計算する
:assign:keyがどのkumo-serverに保存されるかを計算する
:dump:Consistent Hashingのルーティング表を表示する

**kumolog
FIXME
kumologコマンドはバイナリ形式のログを人間にとって読みやすいテキストに変換して表示します。
>||
kumolog [options] <logfile.mpac>
||<

:-f, --follow     :  '''tail -f'''と同じ効果
:-t, --tail       :  最後のN個のログだけ表示する（デフォルト: N=10）
:-h, --head       :  最初のN個のログだけ表示する（デフォルト: N=10）
:-n, --lines=[-]N :  Nを指定する

***ログ
kumo-manager, kumo-server, kumo-gatewayは、それぞれ2種類のログを出力します：
:テキストログ:行区切りのテキストフォーマットのログ。標準出力に出力される
:バイナリログ:MessagePackでシリアライズされたバイナリ形式のログ

テキストログは常に出力されます。''-v''オプションを付けると冗長なログも出力されるようになります。テキストログはファイルに書き出すこともできるが、ログローテーションはサポートしていません。デフォルトでは優先度によってログに色が付きますが、''-d <path.pid>''オプションを指定してデーモンとして起動するか、''-o "-"''オプションを指定すると、ログに色が付かなくなります。

バイナリログは''-g <path.mpac>''オプションを付けたときだけ出力されます。バイナリログはSIGHUPシグナルを受け取るとログファイルを開き直すため、logrotateなどを使ってログローテーションができます。


*FAQ
**kumofsの名前の由来は？
'''kumo'''は空に浮かぶ''雲''を意味しています。'''fs'''はfast storageの略です。

**サーバーに障害が発生したと判断される基準は？
メッセージを送ろうとしたところ、接続済みのすべてのTCPコネクションでエラーが発生し、再接続を試みても失敗して再接続のリトライ回数が上限に達したら、そのノードはダウンしたと判断します。
TCPコネクションが切断されただけではダウンしたとは判断せず、メッセージの送信に失敗しても制限回数以内に再接続することができたら、メッセージは再送されます。
kumo-serverとkumo-managerは常にkeepaliveメッセージをやりとりしており、いつもメッセージを送ろうとしている状態になっています。kumo-managerはkumo-serverがダウンしたらできるだけ早く検出してfaultフラグをセットし、正常なアクセスを継続させます。

**どのkumo-serverにデータを保存するかを決めるアルゴリズムは？
kumofsはConsistent Hashingと呼ばれるアルゴリズムを利用しています。ハッシュ関数はSHA-1で、下位の64ビットのみを使います。1台の物理ノードは128台の仮想ノードを持ちます。

データを取得するときは、kumo-gatewayがkeyにハッシュ関数を掛けてハッシュ表から担当ノードを計算し、担当ノードからデータを取得します。取得に失敗したときは、ハッシュ表上でその次に当たるノードから取得します。それでも失敗したらその次の次のノードから取得します。それでも失敗したら最初の担当ノードに戻ってリトライします。

データを変更するときは、kumo-gatewayがkeyにハッシュ関数を掛けてハッシュ表から担当ノードを計算し、担当ノードにデータを送信します。取得する場合とは異なり、次のノードにフォールバックすることはありません。

担当ノードはSetやDelete操作を受け取ると、データをハッシュ表上で次のノードと、次の次のノードにレプリケーションします。

担当ノードはkumo-gatewayからリクエストを受け取ったとき、本当に自分が担当ノードであるかどうかを自分が持っているハッシュ表を使って確認します。間違っていた場合はリクエストを拒否します。このように必ず特定の担当ノードだけがデータを変更でき、他のノードが同じタイミングで同じkey-valueを変更することがないようになっています。

担当ノードを選ぶときfaultフラグがセットされているノードはスキップします。このため一部の担当ノードがダウンしている状態でも正常なアクセスを続けられます。

// vim: ft=wikiforme
