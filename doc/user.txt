?title kumofs
?author FURUHASHI Sadayuki

?css user.css

*?kumofs user guide

*kumofsとは
kumofsはkey-value型のデータを保存する分散ストレージです。データのレプリケーションをサポートしており、一部のサーバーに障害が発生しても正常に動作し続けます。動作中にサーバーを追加することができ、書き込み・読み込み両方の性能をスケールアウトさせることができます。

*インストール
//kumofsは以下のURLからダウンロードできます

kumofsをコンパイルして実行するには以下の環境が必要です：
-linux >= 2.6.18
-Tokyo Cabinet >= 1.4.10
-ruby >= 1.8
-MessagePack >= 0.3.1
-libcrypto (openssl)
-zlib
-g++ >= 4.1 （コンパイルのみ）
-ragel >= 6.3 (コンパイルのみ)

 ./configure && make && make install でインストールできます。
>|sh|
$ ./configure
$ make
$ sudo make install
||<

*チュートリアル
kumofsは、実際にデータを保存する''Server''ノード、Serverノード群を管理する''Manager''ノード、クライアントホスト上で動作する''Gateway''ノードから構成されます。

Gatewayノードはmemcachedプロトコルをサポートしており、アプリケーションからはlocalhostで動作しているGatewayノードにmemcachedクライアントライブラリを使って接続することでkumofsを利用できます。

s1, s2, s3, s4の4台のホストでServerノードを実行し、m1でManagerを実行し、c1, c2の2台から利用するには、以下のようにします：
>|sh|
[m1]$ kumo-manager -v -l m1
[s1]$ kumo-server  -v -m m1 -l s1 -s database.tch    # -mでManagerを指定する
[s2]$ kumo-server  -v -m m1 -l s2 -s database.tch    # -lは自ホストのアドレス
[s3]$ kumo-server  -v -m m1 -l s3 -s database.tch    # -sはデータベース名
[s4]$ kumo-server  -v -m m1 -l s4 -s database.tch    # -vは冗長なメッセージを出力
[c1]$ kumo-gateway -v -m m1 -t 11211    # 11211/tcpでmemcachedテキストプロトコル
[c2]$ kumo-gateway -v -m m1 -t 11211    # を待ち受ける
||<
kumo-managerとkumo-serverとkumo-gatewayを同じホスト上で動かすこともできます。

kumo-managerは2台のホストで冗長化することができます：
>|sh|
[m1]$ kumo-manager -v -l m1 -p m2    # Manager同士は互いに指定する
[m2]$ kumo-manager -v -l m2 -p m1    # Manager同士は互いに指定する
[s1]$ kumo-server  -v -m m1 -p m2 -l s1 -s database.tch    # -mと-pでManagerを指定する
[s2]$ kumo-server  -v -m m1 -p m2 -l s2 -s database.tch
[s3]$ kumo-server  -v -m m1 -p m2 -l s3 -s database.tch
[s4]$ kumo-server  -v -m m1 -p m2 -l s4 -s database.tch
[c1]$ kumo-gateway -v -m m1 -p m2 -t 11211    # -mと-pでManagerを指定する
[c2]$ kumo-gateway -v -m m1 -p m2 -t 11211
||<

1台のホストで試しに実行してみるには：
>|sh|
[localhost]$ kumo-manager -v -l localhost
[localhost]$ kumo-server  -v -m localhost -l localhost:19801 -L 19901 -s database1.tch
[localhost]$ kumo-server  -v -m localhost -l localhost:19802 -L 19902 -s database2.tch
[localhost]$ kumo-gateway -v -m localhost -t 11211
||<

**Serverノードの追加
動作中にServerノードを追加するには、新しくkumo-serverを起動し、kumoctlコマンドを使って登録します。

kumoctlコマンドにはManagerのアドレス（2台動作しているならどちらか片方）を指定します。
>|sh|
[s5]$ kumo-server -v -m m1 -p m2 -l s5 -s database.tch    # 新しいServerを起動
[xx]$ kumoctl m1 status    # 新しいServerが認識されているか確認
[xx]$ kumoctl m1 attach    # 新しいServerをattach
||<

*障害からの復旧方法
kumofsでは1つのkey-valueのペアは3台のServerノードにコピーされます。そのため2台までならServerノードがダウンしても正常に動作し続けます。

またManagerノードは2台で冗長構成を取ることができます。片方がダウンしても正常に動作し続け、両方ダウンしてもその間にServerに障害が発生しなければ問題なく動作し続けます。

**Serverノードの復旧
Serverノードが1台ダウンすると、一部のkey-valueペアのレプリカが1つ減った状態のまま動作し続けます。2台ダウンすると、1つか2つ減った状態のままになります。この状態からレプリカの数を3つに戻すには、Serverノードを復旧させたあとkumoctlコマンドを使って登録するか、Serverノードを復旧させずにダウンしたServerノードを完全に切り離します。

まずkumoctlコマンドを使ってどのServerノードに障害が発生しているかを確認します：
>|sh|
[xx]$ kumoctl m1 status    # Managerのアドレスを指定して状態を取得
hash space timestamp:
  Wed Dec 03 22:15:35 +0900 2008 clock 50
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (fault)
not attached node:
||<
''(fault)''と表示されているServerノードに障害が発生しています。ここでServerノードを再起動すると、以下のようになります：

>|sh|
[xx]$ kumoctl m1 status
hash space timestamp:
  Wed Dec 03 22:15:45 +0900 2008 clock 58
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (fault)
not attached node:
  192.168.0.104:19800
||<
''not attached node''のところに表示されているServerノードは、Managerノードから認識されているが、システムに登録されていないノードの一覧です。

ここでattachコマンドを発行すると、Serverノードが登録され、復旧されます：
>|sh|
[xx]$ kumoctl m1 status
hash space timestamp:
  Wed Dec 03 22:15:55 +0900 2008 clock 62
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (active)
not attached node:
||<

attachコマンドを発行すると、新たに登録されるServerノードにデータがコピーされることに注意してください。比較的大規模なネットワークトラフィックが発生します。

kumoctlコマンドで、attachコマンドの代わりにdetachコマンドを発行すると、fault状態のServerノードが切り離されます。このときもレプリカの数が3つになるようにデータのコピーが行われます。

FIXME Serverノードを復旧するときにのデータベースファイルの扱い deleteしたデータが復活する件

**Managerノードの復旧
2台で冗長構成を取っているときに片方のManagerノードがダウンした場合は、Managerノードを再起動してください。ManagerノードのIPアドレスは障害発生前と同じにしておく必要があります。

両方のManagerノードがダウンした場合や、Managerノードを1台で運用していてそのManagerノードがダウンした場合は、Managerノードを再起動し、kumoctlコマンドでattachコマンドを発行してください。

*チューニング
**Tokyo Cabinetのチューニング
Tokyo Cabinetのハッシュデータベースのチューニングによって性能は大きく変わります。Serverノードを起動する前に、tchmgrコマンドを使ってデータベースファイルをあらかじめ作成しておいてください。
tchmgrコマンドのパラメータについてはTokyo Cabinetのドキュメントを参照してください。
パラメータの内、拡張メモリマップのサイズ（xmsiz）とキャッシュ機構（rcnum）についてはServerノードのコマンドライン引数で指定します。kumo-serverの''-s''オプションで、データベースファイル名の後ろに''#xmsiz=XXX''と指定すると拡張メモリマップのサイズを指定できます。''#rcnum=XXX''と指定するとキャッシュ機構を有効化できます。
>|sh|
[s2]$ kumo-server  -v -m m1 -l s2 -s database.tch#xmsiz=600m#rcnum=4k
||<

**スレッド数
CPUのハードウェアスレッドの数が多い場合は、kumo-serverとkumo-gatewayのワーカースレッドの数（-TR引数）を増やすと性能が向上する可能性があります。ハードウェアスレッド数+2 くらいが目安です。デフォルトは4です。
送受信するデータのサイズが大きい場合は、kumo-serverとkumo-gatewayの送信用スレッドの数（-TW引数）を増やすと性能が向上する可能性があります。デフォルトは2です。

// FIXME **タイムアウト時間の調節

**非同期レプリケーション
kumofsではデータをsetしたりdeleteしたりするときレプリケーションを行いますが、デフォルトではレプリケーションが完了するまで待ってから（すべてのサーバーから応答が帰ってきてから）アプリケーションに応答が返されます。これをレプリケーションが完了しなくても、1台のServerに書き込みが完了した時点で応答を返すようにすると、更新系の応答速度が大幅に短縮されます。
ただし非同期レプリケーションを有効にすると、成功応答が帰ってきたとしても、必ずしもレプリケーションが成功していることが保証されず、そのため複数のServerノード間でデータの一貫性が保たれているとが保証されなくなります。
Set操作のレプリケーションを非同期にするには、kumo-gatewayのコマンドライン引数に''-As''を、Delete操作のレプリケーションを非同期にするには''-Ad''を追加してください。

*リファレンス
**保証範囲の制限
kumofsはスケーラビリティとアベイラビリティを持つ代わりに、複数のServerノード間に保存されるデータの一貫性に制限があります。保証の範囲外の動作を前提としたアプリケーションを記述しないように注意してください。

***Set
Set操作はkey-valueペアを保存します。
Setが成功応答を返した場合は一貫性は保証されます。つまりすべての担当Serverノードに同じkey-valueペアが書き込まれ、どのノードからでも同じ値を直後にGetすることができ、古い値が読み出されることはありません。
Setが失敗応答を返した場合は一貫性は保証されません。つまりServerノードによって古い値を持っていたり、新しい値を持っていたりします。
Set操作を実行中に同じkeyをGetした場合は、新旧どちらの値が読み出されるかは不定ですが、どちらかの値が読み出されます。混ざった値が読み出されることはありません。

***Delete
Delete操作はkey-valueペアを削除します。
Delete操作は一貫性を保証しませんが、できる限り一貫性が保たれるように努力します。
Delete操作は実際には「deleteフラグ」をSetする操作です。しかしdeleteフラグは時間が経過すると回収され、本当に削除されます。deleteフラグが回収されると一貫性は保証されません。deleteフラグは以下の条件で回収されます：
:Deleteしてから一定の時間が経過した:時間はkumo-serverの''-gX''オプションで指定できます
:Deleteフラグを記憶するメモリ使用量の上限に達し、かつDeleteしてから一定の時間が経過した:時間はkumo-serverの''-gN''オプションで指定できます。メモリ使用量の上限は''-gS''オプションで指定できます

deleteフラグを記憶するメモリ使用量の上限に達したが、Deleteしてから一定の時間が経過していない場合は、deleteフラグはデータベースファイルの中に放置されます。放置されたdeleteフラグは、次に再配置操作が行われたときに回収されます。

**ログ
kumo-manager, kumo-server, kumo-gatewayは、それぞれ2種類のログを出力します：
:テキストログ:行区切りのテキストフォーマットのログ。通常標準出力に出力される
:バイナリログ:MessagePackでシリアライズされたバイナリ形式のログ

テキストログは常に出力されます。''-v''オプションを付けると冗長なログも出力されるようになります。テキストログはファイルに書き出すこともできるが、ログローテーションはサポートしていません。デフォルトでは優先度によってログに色が付きますが、''-d <path.pid>''オプションを指定してデーモンとして起動するか、''-o -''オプションを指定すると、ログに色が付かなくなります。

バイナリログは''-g <path.mpac>''オプションを付けたときだけ出力されます。バイナリログはSIGHUPシグナルを受け取るとログファイルを開き直すため、logrotateなどを使ってログローテーションができます。
// FIXME logrotateの設定例

**configureフラグ
:--with-msgpack=DIR:MessagePackがインストールされているディレクトリを指定する
:--with-tokyocabinet=DIR:Tokyo Cabinetがインストールされているディレクトリを指定する
:--with-tcmalloc[=DIR]:tcmallocとリンクする
:--enable-trace:画面を埋め尽くすほど冗長なデバッグ用のメッセージを出力するようにする

**共通のコマンドライン引数
:-o <path.log>:ログを標準出力ではなく指定されたファイルに出力する。''-''を指定すると標準出力に出力する。省略するとログに色を付けて標準出力に出力する
:-v:WARNよりレベルの低いメッセージを出力する
:-g <path.mpac>:バイナリログを指定されたファイルに出力する
:-d <path.pid>:デーモンになる。指定されたファイルにpidを書き出す
:-Ci <sec>:タイマークロックの間隔を指定する。単位は秒で小数を指定できる
:-Ys <sec>:connect(2)のタイムアウト時間を指定する。単位は秒で小数を指定できる
:-Yn <num>:connect(2)のリトライ回数を指定する
:-TR <num>:ワーカースレッドの数を指定する
:-TW <num>:送信用スレッドの数を指定する

**kumo-manager
:-l <address>:待ち受けるアドレス。''他のノードから見て''接続できるホスト名とポート番号を指定する
:-p <address>:もし存在するなら、もう一台のkumo-managerのホスト名とポート番号を指定する
:-c <port>:kumoctlからのコマンドを受け付けるポート番号を指定する
:-a:Serverが追加・離脱されたときに、マニュアル操作を待たずにレプリケーションの再配置を自動的に行うようにする。実行中でもkumoctlコマンドを使って変更できる
:-Rs:自動的な再配置が有効なときに、サーバーの追加・離脱を検出してからレプリケーションの再配置を開始するまでの待ち時間を指定する。単位は秒

**kumo-server
:-l <address>:待ち受けるアドレス。''他のノードから見て''接続できるホスト名とポート番号を指定する
:-L <port>:kumo-serverが待ち受けるもう一つのポートのポート番号を指定する
:-m <address>:kumo-managerのホスト名とポート番号を指定する
:-p <address>:もし存在するなら、もう一台のkumo-managerのホスト名とポート番号を指定する
:-s <path.tch[#xmsiz=SIZE][#rcnum=SIZE]>:データを保存するデータベースファイルのパスを指定する
:-f <dir>:レプリケーションの再配置に使う一時ファイルを保存するディレクトリを指定する。データベースファイルのサイズに応じて十分な空き容量が必要
:-gS <seconds>:deleteしたエントリのクロックを保持しておくメモリ使用量の上限をKB単位で指定する
:-gN <seconds>:deleteしたエントリのクロックを保持しておく最小時間を指定する。メモリ使用量が上限に達していると、最大時間に満たなくても最小時間を過ぎていれば削除される。
:-gX <seconds>:deleteしたエントリのクロックを保持しておく最大時間を指定する

**kumo-gateway
:-m <address>:kumo-managerのホスト名とポート番号を指定する
:-p <address>:もし存在するなら、もう一台のkumo-managerのホスト名とポート番号を指定する
:-t <port>:memcachedテキストプロトコルを待ち受けるポート番号を指定する
:-b <port>:memcachedバイナリプロトコルを待ち受けるポート番号を指定する（EXPERIMENTAL）
:-G <number>:getの最大リトライ回数を指定する
:-S <number>:setの最大リトライ回数を指定する
:-D <number>:deleteの最大リトライ回数を指定する
:-As:set操作でレプリケーションするとき、レプリケーション完了の応答を待たずに成功を返すようにする
:-Ad:delete操作でレプリケーションするとき、レプリケーション完了の応答を待たずに成功を返すようにする

**kumoctl
kumoctlコマンドはManagerノードに様々なコマンドを発行するための管理コマンドです。
第一引数にManagerノードのアドレスを指定し、第二引数にサブコマンドを指定します。
>|sh|
Usage: kumoctl address[:port=19799] command [options]
command:
   status                     get status
   attach                     attach all new servers and start replace
   attach-noreplace           attach all new servers
   detach                     detach all fault servers and start replace
   detach-noreplace           detach all fault servers
   replace                    start replace without attach/detach
   backup  [suffix=????????]  create backup with specified suffix
   enable-auto-replace        enable auto replace
   disable-auto-replace       disable auto replace
||<

***ハッシュ空間の取得
''status''サブコマンドは、どのServerにデータを保存するかを決定するハッシュ空間を取得します。以下のように表示されます：
>|sh|
hash space timestamp:
  Wed Dec 03 22:15:45 +0900 2008 clock 58
attached node:
  192.168.0.101:19800  (active)
  192.168.0.102:19800  (active)
  192.168.0.103:19800  (active)
  192.168.0.104:19800  (fault)
not attached node:
  192.168.0.104:19800
||<
'''hash space timestamp'''はハッシュ空間を更新した時刻を示しています。
'''attached node'''はシステムに登録されている（ルーティング対象の）Serverノードの一覧を示しています。'''(active)'''はそのノードが利用可能なことを、'''(fault)'''はそのノードがダウンしていることを示します。
'''not attached node'''は認識しているがシステムには登録されていないServerノードの一覧を示しています。

***Serverノードの追加と切り離し
''attach''サブコマンドは、認識しているがシステムには登録されていないServerノードを実際に登録します。''detach''サブコマンドは、fault状態のServerノードをシステムから切り離します。
''attach-noreplace''サブコマンドは''attach''と同じですが、登録した後にレプリカの再配置を行いません。''detach-noreplace''サブコマンドは''detach''と同じですが、登録した後にレプリカの再配置を行いません。''replace''サブコマンドはレプリカの再配置だけを行います。
attach-noreplaceとdetach-noreplaceは、attachとdetachを同時に行いときのみ使用してください。再配置を行わないまま長い間放置してはいけません。

***バックアップの作成
''backup''サブコマンドは、データベースファイルのバックアップを作成します。バックアップは認識しているすべてのServerノード上で作成されます。
バックアップファイルのファイル名は、元のデータベースファイルに第三引数で指定したsuffixを付けたファイル名になります。suffixを省略するとその日の日付(YYMMDD)が使われます。
作成されたバックアップファイルは、''kumomergedb''コマンドを使って1つのファイルにまとめることができます。

**kumolog
kumologコマンドはバイナリ形式のログを人間にとって読みやすいテキストに変換して表示します。
>||
kumolog [options] <logfile.mpac>
||<

:-f, --follow     :  ''tail -f''と同じ効果
:-t, --tail       :  最後のN個のログだけ表示する（デフォルト: N=10）
:-h, --head       :  最初のN個のログだけ表示する（デフォルト: N=10）
:-n, --lines=[-]N :  Nを指定する

**kumostat
kumostatコマンドを使うとServerノードの状態を取得することができます。
第一引数にServerのホスト名とポート番号を指定し、第二引数にコマンドを指定します：
>||
Usage: kumostat address[:port=19800] command [options]
command:
   pid                        get pid of server process
   uptime                     get uptime
   time                       get UNIX time
   version                    get version
   cmd_get                    get number of get requests
   cmd_set                    get number of set requests
   cmd_delete                 get number of delete requests
   items                      get number of stored items
||<

:pid:kumo-serverプロセスのpid
:uptime:kumo-serverプロセスの起動時間（単位は秒）
:time:kumo-serverプロセスが走っているホストのUNIXタイム
:version:kumo-serverのバージョン
:cmd_get:GatewayノードからのGetリクエストを処理した回数
:cmd_set:GatewayノードからのSetリクエストを処理した回数
:cmd_delete:GatewayノードからのDeleteリクエストを処理した回数
:items:データベースに入っているエントリの数

**kumotop
kumotopコマンドを使うとServerノードの状態を定期的に更新しながら表示することができます。
引数に監視したいServerノードのアドレスを指定します。Serverノードのアドレスは複数指定できます：
>||
Usage: kumotop address[:port=19800] ...
||<

**kumomergedb
kumomergedbコマンドを使うと複数のデータベースファイルを1つにまとめることができます。第一引数に出力先のファイル名を指定し、第二引数以降にまとめたいデータベースファイルを指定します。
>|sh|
$ kumomergedb backup.tch-20090101 \
              server1.tch-20090101 server2.tch-20090101 server3.tch-20090101
||<


*?kumofs internals
*分散アルゴリズム
kumofsはどのServerノードにデータを保存するかを決定するために、Consistent Hashingを利用しています。ハッシュ関数はSHA-1で、下位の64ビットのみを使います。1台の物理ノードは128台の仮想ノードを持ちます。

データを取得するときは、Gatewayがkeyにハッシュ関数を掛けてハッシュ空間から担当Serverノードを計算し、担当Serverノードからデータを取得します。取得に失敗したときは、ハッシュ空間上でその次に当たる物理Serverノードから取得します。それでも失敗したらその次の次のServerノードから取得します。それでも失敗したら担当Serverに戻ってリトライします。

データを変更するときは、kGatewayがeyにハッシュ関数を掛けてハッシュ空間から担当Serverノードを計算し、担当Serverノードにデータを送信します。取得する場合とは異なり、次のServerにフォールバックすることはありません。

担当Serverノードは変更操作を受け取ると、データをハッシュ空間上で次の物理Serverノードと、次の次の物理Serverノードにもレプリカをコピーします。

ServerノードはGatewayからリクエストを受け取ったとき、本当に自分が担当ノードであるかどうかを自分が持っているハッシュ空間を使って確認します。間違っていた場合はリクエストを拒否します。

**Serverノードの追加

*死活監視と再配置
**障害の検出

**接続の検出


// vim syntax=wikiforme
